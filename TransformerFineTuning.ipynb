{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4df8f4bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install flair\n",
    "#!pip install torch\n",
    "#!pip install protobuf\n",
    "#!pip install transformers\n",
    "#!pip install sentence-transformers\n",
    "#!pip install dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79f22048",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from flair.data import Sentence\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore') # setting ignore as a parameter\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4d89069a",
   "metadata": {},
   "outputs": [],
   "source": [
    "similar=[\n",
    "(\"A black dog walking beside a pool.\",\"A black dog is walking along the side of a pool.\"),\n",
    "\n",
    "(\"A blonde woman looks for medical supplies for work in a suitcase. \",\" The blond woman is searching for medical supplies in a suitcase.\"),\n",
    "\n",
    "(\"A doubly decker red bus driving down the road.\",\"A red double decker bus driving down a street.\"),\n",
    "\n",
    "(\"There is a black dog jumping into a swimming pool.\",\"A black dog is leaping into a swimming pool.\"),\n",
    "\n",
    "(\"The man used a sword to slice a plastic bottle. \",\"A man sliced a plastic bottle with a sword.\")\n",
    "\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6d0c139b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_df = pd.DataFrame(similar, columns=[\"senl\", \"sen2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b401052",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senl</th>\n",
       "      <th>sen2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A black dog walking beside a pool.</td>\n",
       "      <td>A black dog is walking along the side of a pool.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A blonde woman looks for medical supplies for ...</td>\n",
       "      <td>The blond woman is searching for medical supp...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A doubly decker red bus driving down the road.</td>\n",
       "      <td>A red double decker bus driving down a street.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>There is a black dog jumping into a swimming p...</td>\n",
       "      <td>A black dog is leaping into a swimming pool.</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>The man used a sword to slice a plastic bottle.</td>\n",
       "      <td>A man sliced a plastic bottle with a sword.</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                senl  \\\n",
       "0                 A black dog walking beside a pool.   \n",
       "1  A blonde woman looks for medical supplies for ...   \n",
       "2     A doubly decker red bus driving down the road.   \n",
       "3  There is a black dog jumping into a swimming p...   \n",
       "4   The man used a sword to slice a plastic bottle.    \n",
       "\n",
       "                                                sen2  \n",
       "0   A black dog is walking along the side of a pool.  \n",
       "1   The blond woman is searching for medical supp...  \n",
       "2     A red double decker bus driving down a street.  \n",
       "3       A black dog is leaping into a swimming pool.  \n",
       "4        A man sliced a plastic bottle with a sword.  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "07dba2f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dissimilar= [\n",
    "\n",
    "(\"A little girl and boy are reading books\",\"An older child is playing with the doll while gazing out through window\") ,\n",
    "\n",
    "(\"Two horses standing in a field with trees in the background.\",\"A black and white bird on the body of water with grass in the background.\"),\n",
    "\n",
    "(\"Two people are walking by the ocean\" , \"Two men in fleeces and hats looking at the camera\"),\n",
    "\n",
    "(\"A cat is pouncing on a trampoline\",\"A man is selling tomatoes\"),\n",
    " (\"A woman is riding on a horse\",\"A man is turning over tables in anger\")\n",
    " ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9757c8a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "disim_df = pd.DataFrame(dissimilar, columns=[\"senl\", \"sen2\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ea1416c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>senl</th>\n",
       "      <th>sen2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A little girl and boy are reading books</td>\n",
       "      <td>An older child is playing with the doll while ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Two horses standing in a field with trees in t...</td>\n",
       "      <td>A black and white bird on the body of water wi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Two people are walking by the ocean</td>\n",
       "      <td>Two men in fleeces and hats looking at the camera</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A cat is pouncing on a trampoline</td>\n",
       "      <td>A man is selling tomatoes</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A woman is riding on a horse</td>\n",
       "      <td>A man is turning over tables in anger</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                senl  \\\n",
       "0            A little girl and boy are reading books   \n",
       "1  Two horses standing in a field with trees in t...   \n",
       "2                Two people are walking by the ocean   \n",
       "3                  A cat is pouncing on a trampoline   \n",
       "4                       A woman is riding on a horse   \n",
       "\n",
       "                                                sen2  \n",
       "0  An older child is playing with the doll while ...  \n",
       "1  A black and white bird on the body of water wi...  \n",
       "2  Two men in fleeces and hats looking at the camera  \n",
       "3                          A man is selling tomatoes  \n",
       "4              A man is turning over tables in anger  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "disim_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f11231ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sim(s1,s2):\n",
    "    # cosine similarity function outputs in the range 0-1\n",
    "    s1=s1.embedding.unsqueeze(0)\n",
    "    s2=s2.embedding.unsqueeze(0)\n",
    "    sim = torch.cosine_similarity(s1,s2).item()\n",
    "    return np.round(sim,2)\n",
    "\n",
    "\n",
    "def evaluate (embeddings, myPairList):\n",
    "# it evaluates embeddings for a given list of sentence pair\n",
    "    scores=[]\n",
    "    for s1, s2 in myPairList:\n",
    "        s1,s2=Sentence (s1), Sentence (s2)\n",
    "        embeddings.embed(s1)\n",
    "        embeddings.embed(s2)\n",
    "        score=sim(s1,s2)\n",
    "        scores.append(score)\n",
    "    return scores, np.round(np.mean(scores),2)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21e32e80",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CURL_CA_BUNDLE'] = ''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "21a3c7ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flair.embeddings import WordEmbeddings,DocumentPoolEmbeddings\n",
    "#GLOVE Average Based Embeddings\n",
    "\n",
    "glove_embed = WordEmbeddings('glove')\n",
    "glove_pool_embeds = DocumentPoolEmbeddings([glove_embed])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "98b0b76f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.97, 0.99, 0.97, 0.99, 0.98], 0.98)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(glove_pool_embeds,similar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3aa46288",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([0.91, 0.97, 0.92, 0.85, 0.91], 0.91)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "evaluate(glove_pool_embeds,dissimilar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59f60cc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.98, 1.0, 0.92, 1.0, 0.85], 0.95)\n",
      "([0.61, 1.0, 0.66, 0.12, 0.46], 0.57)\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import WordEmbeddings,DocumentRNNEmbeddings\n",
    "\n",
    "#GRU based embeddings\n",
    "glove_embed = WordEmbeddings('glove')\n",
    "glove_pool_embeds = DocumentRNNEmbeddings([glove_embed])\n",
    "print(evaluate(glove_pool_embeds,similar))\n",
    "print(evaluate(glove_pool_embeds,dissimilar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "29f28f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.85, 0.9, 0.96, 0.91, 0.89], 0.9)\n",
      "([0.88, 0.93, 0.81, 0.91, 0.93], 0.89)\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import TransformerDocumentEmbeddings\n",
    "# Gneral Bert based embeddings\n",
    "bert_embeddings = TransformerDocumentEmbeddings('bert-base-uncased')\n",
    "print(evaluate(bert_embeddings,similar))\n",
    "print(evaluate(bert_embeddings,dissimilar))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c8836ea9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([0.98, 0.95, 0.96, 0.99, 0.98], 0.97)\n",
      "([0.46, 0.41, 0.19, -0.04, 0.01], 0.21)\n"
     ]
    }
   ],
   "source": [
    "from flair.embeddings import SentenceTransformerDocumentEmbeddings\n",
    "#SENTENCE Bert based embeddings\n",
    "sent_bert_embeddings = SentenceTransformerDocumentEmbeddings('bert-base-nli-mean-tokens')\n",
    "print(evaluate(sent_bert_embeddings,similar))\n",
    "print(evaluate(sent_bert_embeddings,dissimilar))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91b54fd6",
   "metadata": {},
   "source": [
    "### FINE TUNING TRANSFORMER MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "047d23aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import SentenceTransformer,util\n",
    "\n",
    "model_id = \"sentence-transformers/all-MiniLM-L6-v2\"\n",
    "model = SentenceTransformer(model_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f8165e95",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dup_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "71b85fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'I_Title', 'D_Title', 'Score', 'Is_Duplicate'], dtype='object')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7aa1b2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=df.drop(['Unnamed: 0'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "b699928b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import fasttext\n",
    "import pandas as pd\n",
    "import re,string\n",
    "from bs4 import BeautifulSoup\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.corpus import wordnet as wn\n",
    "from nltk.tokenize import word_tokenize\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f896a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean_text(input):\n",
    "    input = str(input)\n",
    "    puctuation_pattern = re.compile(r'[%s]'%string.punctuation)\n",
    "    cleantext = BeautifulSoup(input,features=\"html.parser\").text\n",
    "    cleantext = BeautifulSoup(cleantext,features=\"html.parser\").text\n",
    "    html_pattern = re.compile(r'&lt|br|div|&gt|\\r|\\n|\\\\|;|\\d+|/')\n",
    "    input = html_pattern.sub('', cleantext)\n",
    "    input = re.sub(\"-\",\"\",input)\n",
    "    input = re.sub(\"_\",\"\",input)\n",
    "    input = puctuation_pattern.sub('', input)\n",
    "    input = re.sub(r\"\\d+\",'',input)\n",
    "    input = input.lower()\n",
    "    return input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f73e782",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['I_Title'] = df['I_Title'].apply(clean_text)\n",
    "df['D_Title'] = df['D_Title'].apply(clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a96168fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "input=\"RDB AI VALIDATION FOR USER STORY ENTITY jan 16th\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "f996203d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'RDB AI VALIDATION FOR USER STORY ENTITY jan th'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleantext = BeautifulSoup(input,features=\"html.parser\").text\n",
    "cleantext = BeautifulSoup(cleantext,features=\"html.parser\").text\n",
    "cleaned_text = re.sub(r\"\\d+\",\"\", \"RDB AI VALIDATION FOR USER STORY ENTITY jan 16th\")\n",
    "cleaned_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "69c35a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>I_Title</th>\n",
       "      <th>D_Title</th>\n",
       "      <th>Score</th>\n",
       "      <th>Is_Duplicate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>rdb ai validation for user story entity jan th</td>\n",
       "      <td>rdb ai validation for user story entity jan th...</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>rdb ai validation for user story entity jan th</td>\n",
       "      <td>rdb ai validation for user story entity</td>\n",
       "      <td>75.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rdb ai validation for user story entity jan th</td>\n",
       "      <td>rdb ai validation for user story entity jan th</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>story</td>\n",
       "      <td>rra ai backtracking story</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>story</td>\n",
       "      <td>asa th jan story</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1624</th>\n",
       "      <td>new</td>\n",
       "      <td>new product backlog</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1625</th>\n",
       "      <td>new</td>\n",
       "      <td>added new story st feb</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1626</th>\n",
       "      <td>new</td>\n",
       "      <td>new story check</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1627</th>\n",
       "      <td>new</td>\n",
       "      <td>new</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1628</th>\n",
       "      <td>us sanity  march</td>\n",
       "      <td>us  sanity  march</td>\n",
       "      <td>100.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1629 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             I_Title  \\\n",
       "0     rdb ai validation for user story entity jan th   \n",
       "1     rdb ai validation for user story entity jan th   \n",
       "2     rdb ai validation for user story entity jan th   \n",
       "3                                              story   \n",
       "4                                              story   \n",
       "...                                              ...   \n",
       "1624                                             new   \n",
       "1625                                             new   \n",
       "1626                                             new   \n",
       "1627                                             new   \n",
       "1628                                us sanity  march   \n",
       "\n",
       "                                                D_Title  Score  Is_Duplicate  \n",
       "0     rdb ai validation for user story entity jan th...  100.0             1  \n",
       "1               rdb ai validation for user story entity   75.0             0  \n",
       "2        rdb ai validation for user story entity jan th  100.0             1  \n",
       "3                            rra ai backtracking story   100.0             1  \n",
       "4                                      asa th jan story  100.0             1  \n",
       "...                                                 ...    ...           ...  \n",
       "1624                                new product backlog  100.0             1  \n",
       "1625                             added new story st feb  100.0             1  \n",
       "1626                                    new story check  100.0             1  \n",
       "1627                                                new  100.0             1  \n",
       "1628                                  us  sanity  march  100.0             1  \n",
       "\n",
       "[1629 rows x 4 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ac485f40",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    982\n",
       "1    647\n",
       "Name: Is_Duplicate, dtype: int64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Is_Duplicate'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6316fb5a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "814"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(df)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "1074e344",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import InputExample\n",
    "\n",
    "train_examples = []\n",
    "#train_data = dataset['train']['set']\n",
    "# For agility we only 1/2 of our available data\n",
    "n_examples = len(df)//2\n",
    "\n",
    "for i in range(n_examples):\n",
    "    example = list(df.loc[i])\n",
    "    train_examples.append(InputExample(texts=[example[0], example[1]],label=example[3]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "60ab08a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(train_examples, shuffle=True, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "4c007768",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<sentence_transformers.readers.InputExample.InputExample at 0x2441cd1fc70>"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_examples[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "5445049b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sentence_transformers import losses\n",
    "\n",
    "train_loss = losses.ContrastiveLoss(model=model)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0ff21baf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "783febb4f6af439b8c96dd2297d23dc9",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Epoch:   0%|          | 0/10 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e417197b7b564ec79f0b74c0a4d1eaa2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "712786527bc44a1aaea955af67711136",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "990ff9eb5c3242c49446c1206da1816f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ca0ecccb83bb4ce68f3e9d1aa73db2fc",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d85abde8deb24a0eb62f2aae2cead863",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "72792132b110464aa82074d8ee62b532",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aaf74e55d4c9412da82c4a5fb0d96c6c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f56bcbb4dd5b4c359de42b9a875596b3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6001b740a92441f1a51a3b33ce01c9f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "78f1a74b11a24328b5134a5585b0d766",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Iteration:   0%|          | 0/51 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.fit(train_objectives=[(train_dataloader, train_loss)], epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0a9ef030",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_examples1 = len(df)//2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1c0c349e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9639]])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d= model.encode([\"rra ai Validation\",\" rra ai data validation\"])\n",
    "cos_sim = util.cos_sim(d[0],d[1])\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "0834751b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.6789]])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x=\"story entity \"\n",
    "y=\"rdb ai validation for user story entity\"\n",
    "d= model.encode([x,y])\n",
    "cos_sim = util.cos_sim(d[0],d[1])\n",
    "cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf063f9",
   "metadata": {},
   "source": [
    "BUILDING MODEL FOR PREDICTION DUPLICATE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4447c112",
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "721d3b5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pip install daal==2021.4.0\n",
    "#pip install numpy==1.21.6\n",
    "#!pip install packaging>=21.3\n",
    "#import tensorflow as tf\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ce60b8e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "3f62a906",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_length = 256  # Maximum length of input sentence to the model.\n",
    "batch_size = 32\n",
    "epochs = 2\n",
    "\n",
    "# Labels in our dataset.\n",
    "labels = [0, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6d7741e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1629, 4)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "3e2393d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "cb2319c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X= df.drop(columns=['Is_Duplicate',\"Score\"],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4d17707b",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y= df.drop(columns=['I_Title','D_Title','Score'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977280a3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edb5cad3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "b6c3881e",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=1)\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.25, random_state=1) # 0.25 x 0.8 = 0.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6a0d358",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3e7e7d04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of missing values\n",
      "I_Title    0\n",
      "D_Title    0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Number of missing values\")\n",
    "print(X_train.isnull().sum())\n",
    "X_train.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "a06db87f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Target Distribution\n",
      "0    584\n",
      "1    393\n",
      "Name: Is_Duplicate, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(\"Train Target Distribution\")\n",
    "print(y_train.Is_Duplicate.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "fd203251",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_df = (\n",
    "#     train_df[train_df.Is_Duplicate != \"-\"]\n",
    "#     .sample(frac=1.0, random_state=42)\n",
    "#     .reset_index(drop=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "ae7bf9c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = tf.keras.utils.to_categorical(y_train.Is_Duplicate, num_classes=2)\n",
    "y_val = tf.keras.utils.to_categorical(y_val.Is_Duplicate, num_classes=2)\n",
    "y_test = tf.keras.utils.to_categorical(y_test.Is_Duplicate, num_classes=2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "8de40b3d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "I_Title               story\n",
      "D_Title    asa th jan story\n",
      "Name: 4, dtype: object\n",
      "[0. 1.]\n"
     ]
    }
   ],
   "source": [
    "print(X_train.iloc[567])\n",
    "print(y_train[567])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be6edf1b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6c8f9a8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BertSemanticDataGenerator(tf.keras.utils.Sequence):\n",
    "    \"\"\"Generates batches of data.\n",
    "\n",
    "    Args:\n",
    "        sentence_pairs: Array of premise and hypothesis input sentences.\n",
    "        labels: Array of labels.\n",
    "        batch_size: Integer batch size.\n",
    "        shuffle: boolean, whether to shuffle the data.\n",
    "        include_targets: boolean, whether to incude the labels.\n",
    "\n",
    "    Returns:\n",
    "        Tuples `([input_ids, attention_mask, `token_type_ids], labels)`\n",
    "        (or just `[input_ids, attention_mask, `token_type_ids]`\n",
    "         if `include_targets=False`)\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        sentence_pairs,\n",
    "        labels,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        include_targets=True,\n",
    "    ):\n",
    "        self.sentence_pairs = sentence_pairs\n",
    "        self.labels = labels\n",
    "        self.shuffle = shuffle\n",
    "        self.batch_size = batch_size\n",
    "        self.include_targets = include_targets\n",
    "        # Load our BERT Tokenizer to encode the text.\n",
    "        # We will use base-base-uncased pretrained model.\n",
    "        self.tokenizer = transformers.BertTokenizer.from_pretrained(\n",
    "            \"bert-base-uncased\", do_lower_case=True\n",
    "        )\n",
    "        self.indexes = np.arange(len(self.sentence_pairs))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        # Denotes the number of batches per epoch.\n",
    "        return len(self.sentence_pairs) // self.batch_size\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # Retrieves the batch of index.\n",
    "        indexes = self.indexes[idx * self.batch_size : (idx + 1) * self.batch_size]\n",
    "        sentence_pairs = self.sentence_pairs[indexes]\n",
    "\n",
    "        # With BERT tokenizer's batch_encode_plus batch of both the sentences are\n",
    "        # encoded together and separated by [SEP] token.\n",
    "        encoded = self.tokenizer.batch_encode_plus(\n",
    "            sentence_pairs.tolist(),\n",
    "            add_special_tokens=True,\n",
    "            max_length=max_length,\n",
    "            return_attention_mask=True,\n",
    "            return_token_type_ids=True,\n",
    "            pad_to_max_length=True,\n",
    "            return_tensors=\"tf\",\n",
    "        )\n",
    "\n",
    "        # Convert batch of encoded features to numpy array.\n",
    "        input_ids = np.array(encoded[\"input_ids\"], dtype=\"int32\")\n",
    "        attention_masks = np.array(encoded[\"attention_mask\"], dtype=\"int32\")\n",
    "        token_type_ids = np.array(encoded[\"token_type_ids\"], dtype=\"int32\")\n",
    "\n",
    "        # Set to true if data generator is used for training/validation.\n",
    "        if self.include_targets:\n",
    "            labels = np.array(self.labels[indexes], dtype=\"int32\")\n",
    "            return [input_ids, attention_masks, token_type_ids], labels\n",
    "        else:\n",
    "            return [input_ids, attention_masks, token_type_ids]\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        # Shuffle indexes after each epoch if shuffle is set to True.\n",
    "        if self.shuffle:\n",
    "            np.random.RandomState(42).shuffle(self.indexes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "5d902b41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:There are non-GPU devices in `tf.distribute.Strategy`, not using nccl allreduce.\n",
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:CPU:0',)\n",
      "Strategy: <tensorflow.python.distribute.mirrored_strategy.MirroredStrategy object at 0x0000024422921880>\n",
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer)    [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n",
      "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 256, 128)     426496      ['bert[0][0]']                   \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['bidirectional[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['bidirectional[0][0]']          \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 , 'global_max_pooling1d[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 256)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            514         ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,909,250\n",
      "Trainable params: 427,010\n",
      "Non-trainable params: 109,482,240\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Create the model under a distribution strategy scope.\n",
    "strategy = tf.distribute.MirroredStrategy()\n",
    "\n",
    "with strategy.scope():\n",
    "    # Encoded token ids from BERT tokenizer.\n",
    "    input_ids = tf.keras.layers.Input(\n",
    "        shape=(max_length,), dtype=tf.int32, name=\"input_ids\"\n",
    "    )\n",
    "    # Attention masks indicates to the model which tokens should be attended to.\n",
    "    attention_masks = tf.keras.layers.Input(\n",
    "        shape=(max_length,), dtype=tf.int32, name=\"attention_masks\"\n",
    "    )\n",
    "    # Token type ids are binary masks identifying different sequences in the model.\n",
    "    token_type_ids = tf.keras.layers.Input(\n",
    "        shape=(max_length,), dtype=tf.int32, name=\"token_type_ids\"\n",
    "    )\n",
    "    # Loading pretrained BERT model.\n",
    "    bert_model = transformers.TFBertModel.from_pretrained(\"bert-base-uncased\")\n",
    "    # Freeze the BERT model to reuse the pretrained features without modifying them.\n",
    "    bert_model.trainable = False\n",
    "\n",
    "    bert_output = bert_model.bert(\n",
    "        input_ids, attention_mask=attention_masks, token_type_ids=token_type_ids\n",
    "    )\n",
    "    sequence_output = bert_output.last_hidden_state\n",
    "    pooled_output = bert_output.pooler_output\n",
    "    # Add trainable layers on top of frozen layers to adapt the pretrained features on the new data.\n",
    "    bi_lstm = tf.keras.layers.Bidirectional(\n",
    "        tf.keras.layers.LSTM(64, return_sequences=True)\n",
    "    )(sequence_output)\n",
    "    # Applying hybrid pooling approach to bi_lstm sequence output.\n",
    "    avg_pool = tf.keras.layers.GlobalAveragePooling1D()(bi_lstm)\n",
    "    max_pool = tf.keras.layers.GlobalMaxPooling1D()(bi_lstm)\n",
    "    concat = tf.keras.layers.concatenate([avg_pool, max_pool])\n",
    "    dropout = tf.keras.layers.Dropout(0.3)(concat)\n",
    "    output = tf.keras.layers.Dense(2, activation=\"softmax\")(dropout)\n",
    "    model = tf.keras.models.Model(\n",
    "        inputs=[input_ids, attention_masks, token_type_ids], outputs=output\n",
    "    )\n",
    "\n",
    "    model.compile(\n",
    "        optimizer=tf.keras.optimizers.Adam(),\n",
    "        loss=\"categorical_crossentropy\",\n",
    "        metrics=[\"acc\"],\n",
    "    )\n",
    "\n",
    "\n",
    "print(f\"Strategy: {strategy}\")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "00df1a65",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = BertSemanticDataGenerator(\n",
    "    X_train[[\"I_Title\", \"D_Title\"]].values.astype(\"str\"),\n",
    "    y_train,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "valid_data = BertSemanticDataGenerator(\n",
    "    X_val[[\"I_Title\", \"D_Title\"]].values.astype(\"str\"),\n",
    "    y_val,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=False,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36098c71",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "30/30 [==============================] - 622s 20s/step - loss: 0.4593 - acc: 0.7750 - val_loss: 0.3261 - val_acc: 0.8438\n",
      "Epoch 2/2\n",
      "30/30 [==============================] - 756s 26s/step - loss: 0.2981 - acc: 0.8740 - val_loss: 0.2625 - val_acc: 0.9094\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=True,\n",
    "    workers=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b5753b50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                   Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      " input_ids (InputLayer)         [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " attention_masks (InputLayer)   [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " token_type_ids (InputLayer)    [(None, 256)]        0           []                               \n",
      "                                                                                                  \n",
      " bert (TFBertMainLayer)         TFBaseModelOutputWi  109482240   ['input_ids[0][0]',              \n",
      "                                thPoolingAndCrossAt               'attention_masks[0][0]',        \n",
      "                                tentions(last_hidde               'token_type_ids[0][0]']         \n",
      "                                n_state=(None, 256,                                               \n",
      "                                 768),                                                            \n",
      "                                 pooler_output=(Non                                               \n",
      "                                e, 768),                                                          \n",
      "                                 past_key_values=No                                               \n",
      "                                ne, hidden_states=N                                               \n",
      "                                one, attentions=Non                                               \n",
      "                                e, cross_attentions                                               \n",
      "                                =None)                                                            \n",
      "                                                                                                  \n",
      " bidirectional (Bidirectional)  (None, 256, 128)     426496      ['bert[0][0]']                   \n",
      "                                                                                                  \n",
      " global_average_pooling1d (Glob  (None, 128)         0           ['bidirectional[0][0]']          \n",
      " alAveragePooling1D)                                                                              \n",
      "                                                                                                  \n",
      " global_max_pooling1d (GlobalMa  (None, 128)         0           ['bidirectional[0][0]']          \n",
      " xPooling1D)                                                                                      \n",
      "                                                                                                  \n",
      " concatenate (Concatenate)      (None, 256)          0           ['global_average_pooling1d[0][0]'\n",
      "                                                                 , 'global_max_pooling1d[0][0]']  \n",
      "                                                                                                  \n",
      " dropout_37 (Dropout)           (None, 256)          0           ['concatenate[0][0]']            \n",
      "                                                                                                  \n",
      " dense (Dense)                  (None, 2)            514         ['dropout_37[0][0]']             \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 109,909,250\n",
      "Trainable params: 109,909,250\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "bert_model.trainable = True\n",
    "# Recompile the model to make the change effective.\n",
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(1e-5),\n",
    "    loss=\"categorical_crossentropy\",\n",
    "    metrics=[\"accuracy\"],\n",
    ")\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6002f7cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/2\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "WARNING:tensorflow:Gradients do not exist for variables ['tf_bert_model/bert/pooler/dense/kernel:0', 'tf_bert_model/bert/pooler/dense/bias:0'] when minimizing the loss. If you're using `model.compile()`, did you forget to provide a `loss` argument?\n",
      "30/30 [==============================] - 2114s 69s/step - loss: 0.2003 - accuracy: 0.9198 - val_loss: 0.1717 - val_accuracy: 0.9406\n",
      "Epoch 2/2\n",
      "30/30 [==============================] - 2587s 87s/step - loss: 0.1151 - accuracy: 0.9625 - val_loss: 0.1282 - val_accuracy: 0.9438\n"
     ]
    }
   ],
   "source": [
    "# Unfreeze the bert_model.\n",
    "history = model.fit(\n",
    "    train_data,\n",
    "    validation_data=valid_data,\n",
    "    epochs=epochs,\n",
    "    use_multiprocessing=True,\n",
    "    workers=-1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "41c5462f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_similarity(sentence1, sentence2):\n",
    "    sentence_pairs = np.array([[str(sentence1), str(sentence2)]])\n",
    "    test_data = BertSemanticDataGenerator(\n",
    "        sentence_pairs, labels=None, batch_size=1, shuffle=False, include_targets=False,\n",
    "    )\n",
    "\n",
    "    proba = model.predict(test_data[0])[0]\n",
    "    idx = np.argmax(proba)\n",
    "    proba = f\"{proba[idx]: .2f}%\"\n",
    "    pred = labels[idx]\n",
    "    return pred, proba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "1577f40d",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=\"rsp app service data Validation\"\n",
    "s2 =\"rsp service data Validation\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d19a4918",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 738ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, ' 0.93%')"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_similarity(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "8a9ac58e",
   "metadata": {},
   "outputs": [],
   "source": [
    "s1=\"data Validation\"\n",
    "s2=\"rra ai backtracking story\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "17f3d12a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 685ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(0, ' 0.97%')"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_similarity(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "3f1df2d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 698ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, ' 0.98%')"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1=\"A black dog walking beside a pool.\"\n",
    "s2=\"A black dog is walking along the side of a pool.\"\n",
    "check_similarity(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "59a469ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 1s 846ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, ' 0.96%')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s1=\"A woman is riding on a horse\"\n",
    "s2=\"A man is turning over tables in anger\"\n",
    "check_similarity(s1,s2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "34ea1800",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A woman is riding on a horse'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e6dcb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
